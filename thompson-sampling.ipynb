{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import random\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, data_info, shuffle=True):\n",
    "    \"\"\"Preprocesses the input data.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of pandas DataFrames to be concatenated.\n",
    "        data_info (dict): Information about the data setup.\n",
    "        shuffle (bool, optional): Whether to shuffle the data. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Preprocessed dataset.\n",
    "    \"\"\"\n",
    "    df = pd.concat([df for df in data])\n",
    "    ad_sets = df[data_info[\"groups\"]].unique()\n",
    "    np.random.shuffle(ad_sets)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = pd.DataFrame(columns=df.columns)\n",
    "        for ad in ad_sets:\n",
    "            ad_df = df[df[data_info[\"groups\"]] == ad].sort_values(data_info[\"sort_by\"])\n",
    "            dataset = pd.concat([dataset, ad_df])\n",
    "\n",
    "        dtypes = df.dtypes\n",
    "        dataset = dataset.astype(dtypes)\n",
    "    else:\n",
    "        dataset = df.copy()\n",
    "\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    return dataset\n",
    "\n",
    "def load_model_parameters(load_path=\"model_parameters.pkl\"):\n",
    "    \"\"\"Load trained model parameters from a file.\"\"\"\n",
    "    with open(load_path, \"rb\") as file:\n",
    "        models = pickle.load(file)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "PROCESSING_INFO = config_data['PROCESSING_INFO']\n",
    "TRAIN_INFO = config_data['TRAIN_INFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [\n",
    "    \"test_15-17.02.2024.csv\"\n",
    "]\n",
    "\n",
    "DATA = [pd.read_csv(f\"./processed/{path}\") for path in PATHS]\n",
    "MODEL = load_model_parameters()[\"Gradient Boosting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \"\"\"Represents an action with successes and failures, supporting Bayesian updates.\"\"\"\n",
    "    def __init__(self, successes=1, failures=1):\n",
    "        self.successes = successes\n",
    "        self.failures = failures\n",
    "\n",
    "    def sample(self, num_samples=1):\n",
    "        \"\"\"Samples from the Beta distribution defined by the action's successes and failures.\"\"\"\n",
    "        beta_samples = np.random.beta(self.successes, self.failures, size=num_samples)\n",
    "        if num_samples == 1:\n",
    "            return beta_samples[0]    \n",
    "        return beta_samples\n",
    "\n",
    "    def update(self, success, failure):\n",
    "        \"\"\"Updates the action's successes and failures.\"\"\"\n",
    "        self.successes += success\n",
    "        self.failures += failure\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"Returns the current successes and failures.\"\"\"\n",
    "        return self.successes, self.failures\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Returns a string representation of the action.\"\"\"\n",
    "        return f\"Action(s={self.successes}, f={self.failures})\"\n",
    "\n",
    "\n",
    "class AdSet:\n",
    "    \"\"\"Represents a set of advertisement data with associated Action instance.\"\"\"\n",
    "    def __init__(self, successful, data, action):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self._successful = successful\n",
    "        self._record = 0\n",
    "        self.action = action\n",
    "\n",
    "    def get_record(self):\n",
    "        \"\"\"Retrieves the current advertisement metrics record for adset performance evaluation.\"\"\"\n",
    "        record = self.data.iloc[self._record, :]\n",
    "        self._record += 1\n",
    "        return record\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Provides a string representation of the AdSet\"\"\"\n",
    "        return f\"AdSet(successful={self._successful}, record={self._record})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(record, model=MODEL, train_info=TRAIN_INFO):\n",
    "    \"\"\"\n",
    "    Converts a record or multiple records into a binary format based on the model's prediction.\n",
    "    \n",
    "    Args:\n",
    "        record (pd.Series or pd.DataFrame): The input data to be binarized. \n",
    "        Can be a single record (pd.Series) or multiple records (pd.DataFrame).\n",
    "        model (Model): The predictive model used for binarization. Must have a predict method that accepts numpy arrays.\n",
    "        train_info (dict): A dictionary containing training information. \n",
    "        Must include a key \"train_fields\" that specifies the fields in the record to be used by the model.\n",
    "    \n",
    "    Returns:\n",
    "        int or np.ndarray: The predicted binary outcome(s).\n",
    "    \"\"\"\n",
    "    if record.ndim == 1:\n",
    "        context = record.loc[train_info[\"train_fields\"]].to_numpy().reshape(1, -1)\n",
    "        return model.predict(context)[0]\n",
    "    elif record.ndim == 2:\n",
    "        context = record.loc[:, train_info[\"train_fields\"]].to_numpy()\n",
    "        return model.predict(context)   \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(DATA, TRAIN_INFO)\n",
    "\n",
    "TEST_FIELD = TRAIN_INFO[\"label_field\"]\n",
    "GROUPS = TRAIN_INFO[\"groups\"]\n",
    "\n",
    "good = random.sample(sorted(data[data[TEST_FIELD] == 1][GROUPS].unique()), data[data[TEST_FIELD] == 1][GROUPS].nunique())\n",
    "bad = random.sample(sorted(data[data[TEST_FIELD] == 0][GROUPS].unique()), data[data[TEST_FIELD] == 0][GROUPS].nunique())\n",
    "\n",
    "max_timestamps = data.groupby(GROUPS)[\"hour\"].count().max()\n",
    "\n",
    "adsets = []\n",
    "\n",
    "for ad in bad:\n",
    "    adset = AdSet(0, data[data[GROUPS] == ad], Action())\n",
    "    adsets.append(adset)\n",
    "\n",
    "for ad in good:\n",
    "    adset = AdSet(1, data[data[GROUPS] == ad], Action())\n",
    "    adsets.append(adset)\n",
    "\n",
    "history = {}\n",
    "\n",
    "for timestamp in range(max_timestamps):\n",
    "\n",
    "    history[timestamp] = deepcopy(adsets)\n",
    "\n",
    "    for ad in adsets:\n",
    "        record = ad.get_record()\n",
    "        reward = binarize(record)\n",
    "        ad.action.update(reward, 1 - reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a8f9e9e8c3422385613587fa5bc8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='timestamp', max=71), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_plot(timestamp)>"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional Methods for visualization\n",
    "def plot_distribution(timestamp, adsets):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Distribution Plot at hour # {timestamp} (red - \"successful\", blue - \"unsuccessful\")')\n",
    "    \n",
    "    for i, ad in enumerate(adsets):\n",
    "        samples = ad.action.sample(10000)\n",
    "        sns.kdeplot(samples, fill=True, label=f'Adset {ad}', color='red' if ad._successful == 0 else \"blue\")\n",
    "    \n",
    "    plt.xlabel('Success Probability')\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "def interactive_plot(timestamp):\n",
    "    adsets_ = history[timestamp]\n",
    "    plot_distribution(timestamp, adsets_)\n",
    "\n",
    "interact(interactive_plot, timestamp=IntSlider(min=0, max=max_timestamps-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:\t 100.00%\n",
      "accuracy_score:\t\t 97.67%\n",
      "f1_score:\t\t 97.14%\n",
      "confusion_matrix:\n",
      " [[25  0]\n",
      " [ 1 17]]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for ad in adsets:\n",
    "    alpha = ad.action.successes\n",
    "    beta = ad.action.failures\n",
    "    mu = alpha / (alpha + beta)\n",
    "    value = 1 if mu > 0.7 else 0\n",
    "    \n",
    "    y_true.append(ad._successful)\n",
    "    y_pred.append(value)\n",
    "\n",
    "print(\"precision_score:\\t\",  f\"{precision_score(y_true, y_pred):.2%}\")\n",
    "print(\"accuracy_score:\\t\\t\", f\"{accuracy_score(y_true, y_pred):.2%}\")\n",
    "print(\"f1_score:\\t\\t\",       f\"{f1_score(y_true, y_pred):.2%}\")\n",
    "print(\"confusion_matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
